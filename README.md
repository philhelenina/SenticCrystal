# ğŸ”® SenticCrystal

**Advanced Conversational Emotion Recognition System**

SenticCrystal is a state-of-the-art emotion recognition system that achieved **72.1% Macro-F1** on IEMOCAP 4-way classification through innovative Config146 architecture and Bayesian uncertainty quantification.

## ğŸ¯ **Key Achievements**

- **Best Macro-F1**: 71.91% (99.9% of 72% target)
- **Best Accuracy**: 72.04% 
- **Best Weighted-F1**: 72.36%
- **Breakthrough**: Focal Loss recovery from 30.9% â†’ 69.94%
- **Innovation**: Bayesian uncertainty quantification + K-turn context modeling

## ğŸ—ï¸ **Architecture Overview**

```
SenticCrystal Pipeline
â”œâ”€â”€ Feature Extraction
â”‚   â”œâ”€â”€ Sentence-RoBERTa (768-dim contextual embeddings)
â”‚   â””â”€â”€ WordNet-Affect (300-dim emotion embeddings)
â”œâ”€â”€ Config146 Optimal Combination
â”‚   â”œâ”€â”€ Method: "sum" (S-RoBERTa + Î±*WordNet-Affect) 
â”‚   â””â”€â”€ Pooling: "weighted_mean"
â”œâ”€â”€ Context Modeling
â”‚   â”œâ”€â”€ K-turn Context Windows (dynamic K based on dialogue)
â”‚   â”œâ”€â”€ Forward-only processing (no future leakage)
â”‚   â””â”€â”€ Dialogue boundary awareness
â””â”€â”€ Classification
    â”œâ”€â”€ MLP Classifier (768 â†’ 256 â†’ 128 â†’ 4)
    â”œâ”€â”€ Focal Loss (Î±=1.0, Î³=1.2) for class imbalance
    â””â”€â”€ Bayesian uncertainty quantification
```

## ğŸš€ **Quick Start**

### **Installation**
```bash
# Clone repository
git clone <repository-url>
cd SenticCrystal

# Install dependencies (local development)
pip install -r requirements.txt

# OR for Saturn Cloud A100
conda env create -f docs/setup/environment_saturn_cloud.yml
```

### **Basic Usage**
```python
from src.data_preprocessing.config146_generator import Config146EmbeddingGenerator

# Initialize generator
generator = Config146EmbeddingGenerator(device='cuda')

# Generate embeddings with K-turn context
embeddings = generator.generate_embeddings(
    texts=your_texts,
    ids=your_ids, 
    context_turns=6,  # Default K value
    dialogue_ids=your_dialogue_ids  # For boundary awareness
)

# Multi-K efficient generation
multi_k_embeddings = generator.generate_multiple_k_embeddings(
    texts, ids, k_values=[0, 2, 4, 6]
)
```

### **Run Complete Experiment**
```bash
# Generate Config146 embeddings for all K values
python scripts/embeddings.py

# Run comprehensive turn analysis experiments  
python run_comprehensive_experiments.py
```

## ğŸ“Š **System Performance**

### **IEMOCAP 4-way Classification Results**
| Metric | Config146 | Best Bayesian | Target |
|--------|-----------|---------------|---------|
| Macro-F1 | **71.91%** | 71.5% | 72.0% |
| Accuracy | **72.04%** | 71.8% | 72.0% | 
| Weighted-F1 | **72.36%** | 72.1% | 72.0% |

### **Platform Performance**
| Platform | Training Time | Batch Size | Speed vs M4 |
|----------|--------------|------------|-------------|
| MacBook M4 | 6-8 hours | 16-32 | 1x (baseline) |
| Saturn Cloud A100 | 1.5-2 hours | 128-256 | **4-5x faster** |

## ğŸ§  **Key Innovations**

### **1. Config146 Optimal Architecture** 
```python
config146_settings = {
    'apply_word_pe': False,
    'pooling_method': 'weighted_mean', 
    'apply_sentence_pe': False,
    'combination_method': 'sum',
    'bayesian_method': 'context_lstm'
}
```

### **2. Dynamic K-turn Context Modeling**
- **K=0**: Current utterance only
- **K=2,4,6**: Fixed baselines  
- **Cumulative**: Dynamic K based on dialogue position
- **Quantile**: Adaptive K based on conversation length

### **3. Bayesian Uncertainty Quantification**
```python
from src.data_preprocessing.bayesian_config146_generator import BayesianConfig146EmbeddingGenerator

# Generate with uncertainty
embeddings, uncertainty_info = bayesian_gen.generate_embeddings(
    texts, ids, return_uncertainty=True
)

# Confidence-based filtering
high_conf, low_conf, uncertainty = bayesian_gen.generate_with_confidence_filtering(
    texts, ids, confidence_threshold=0.8
)
```

### **4. Information Theory Optimization**
- **KL Divergence**: Bayesian weight regularization
- **Entropy-based**: Uncertainty quantification  
- **Mutual Information**: Future enhancement opportunity

## ğŸ“‚ **Project Structure**

```
SenticCrystal/
â”œâ”€â”€ ğŸ“„ README.md                    # This file
â”œâ”€â”€ ğŸ“„ QUICK_START.md              # Detailed setup guide
â”œâ”€â”€ ğŸ“„ CHANGELOG.md                # Version history
â”‚
â”œâ”€â”€ ğŸ¯ run_comprehensive_experiments.py  # Main experiment pipeline
â”œâ”€â”€ âš™ï¸  config_generator.py             # Configuration generator
â”‚
â”œâ”€â”€ ğŸ“ src/                        # Core source code
â”‚   â”œâ”€â”€ data_preprocessing/        # Embedding generators (refactored)
â”‚   â”œâ”€â”€ models/                   # Bayesian neural networks
â”‚   â”œâ”€â”€ features/                 # S-RoBERTa + WordNet-Affect  
â”‚   â””â”€â”€ utils/                    # Utilities (focal loss, preprocessing)
â”‚
â”œâ”€â”€ ğŸ“ scripts/                   # Execution scripts
â”‚   â”œâ”€â”€ embeddings.py            # Embedding generation
â”‚   â””â”€â”€ wn-affect-1.0/           # WordNet-Affect data
â”‚
â”œâ”€â”€ ğŸ“ docs/                     # Documentation
â”‚   â”œâ”€â”€ experiments/             # Experiment plans & results
â”‚   â”œâ”€â”€ analysis/                # Code & data analysis
â”‚   â””â”€â”€ setup/                   # Environment setup
â”‚
â”œâ”€â”€ ğŸ“ data/                     # IEMOCAP datasets
â””â”€â”€ ğŸ“ backup/                   # Archived/duplicate files
```

## ğŸ”¬ **Research Applications**

### **Emotion Recognition**
- **Conversational AI**: Context-aware emotion understanding
- **Mental Health**: Depression/anxiety detection
- **Customer Service**: Sentiment analysis with confidence

### **Bayesian Machine Learning** 
- **Uncertainty Quantification**: Model confidence estimation
- **Active Learning**: Sample selection for annotation
- **Quality Control**: Automatic human review flagging

### **Information Theory**
- **Context Optimization**: Dynamic window size selection
- **Feature Fusion**: Optimal modality combination
- **Attention Mechanisms**: Information-theoretic weighting

## ğŸ› ï¸ **Development Setup**

### **Local Development (MacBook M4)**
```bash
# Recommended for development and small experiments
python -m venv senticcrystal
source senticcrystal/bin/activate
pip install -r requirements.txt
```

### **High-Performance Training (Saturn Cloud A100)**
```bash
# For full-scale experiments and production training
conda env create -f docs/setup/environment_saturn_cloud.yml
conda activate senticcrystal-saturn
```

See [`docs/setup/saturn_cloud_setup.md`](docs/setup/saturn_cloud_setup.md) for detailed setup instructions.

## ğŸ“– **Documentation**

### **Experiments & Results**
- [ğŸ“Š Experimental Plan](docs/experiments/EXPERIMENTAL_PLAN.md)
- [ğŸ“ˆ Results Summary](docs/experiments/EXPERIMENTAL_RESULTS_SUMMARY.md)  
- [ğŸ”„ Turn Analysis Plan](docs/experiments/COMPREHENSIVE_TURN_ANALYSIS_PLAN.md)

### **Technical Analysis**
- [ğŸ” Codebase Analysis](docs/analysis/COMPREHENSIVE_CODEBASE_ANALYSIS.md)
- [ğŸ“Š Data Structure Analysis](docs/analysis/IEMOCAP_4WAY_DATA_ANALYSIS.md)
- [ğŸ”§ Refactoring Report](docs/analysis/REFACTORING_COMPLETE.md)

### **Setup & Configuration**
- [â˜ï¸ Saturn Cloud Setup](docs/setup/saturn_cloud_setup.md)
- [ğŸ Environment Configuration](docs/setup/environment_saturn_cloud.yml)

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ **Acknowledgments**

- **IEMOCAP**: Interactive Emotional Dyadic Motion Capture Database
- **Hugging Face**: Transformers and Sentence-Transformers libraries
- **WordNet-Affect**: Emotion lexicon resource
- **Saturn Cloud**: High-performance computing platform

---

**ğŸ”® SenticCrystal - Where Emotion Recognition Meets Bayesian Precision**