# SenticCrystal
An information-theoretic framework for crystallizing the core principles of emotion from text and speech.

# SenticCrystal

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

## ğŸ“Œ Overview

**SenticCrystal** is an information-theoretic framework for emotion recognition that "crystallizes" the essential principles of emotion from complex text and speech data. Through systematic experiments, we discovered that simpler, interpretable models can achieve performance comparable to complex architectures, leading to our core philosophy: **finding clarity in complexity**.

### Key Achievements
- **73.25% accuracy** on IEMOCAP 4-way emotion classification (text-only)
- **Complete model recovery** from catastrophic failure (30.9% â†’ 69.94%) using Focal Loss optimization
- **Balanced classification** across all emotion classes (eliminating 10-80% class bias)

## ğŸ¯ Core Philosophy

SenticCrystal embodies three fundamental principles:

1. **Simplicity over Complexity**: Our experiments demonstrate that interpretable models with proper optimization outperform unnecessarily complex architectures
2. **Information Crystallization**: We extract and preserve only the essential information for emotion recognition, removing noise and redundancy
3. **Balanced Understanding**: Through Focal Loss optimization (Î±=1.0, Î³=1.2), we achieve balanced performance across all emotion classes

## ğŸ—ï¸ Project Structure

```
SenticCrystal/
â”‚
â”œâ”€â”€ src/                          # Core reusable components
â”‚   â”œâ”€â”€ models/                   # Model architectures
â”‚   â”‚   â”œâ”€â”€ mlp.py               # MLP classifier with Focal Loss
â”‚   â”‚   â”œâ”€â”€ lstm_context.py      # Contextual LSTM implementations
â”‚   â”‚   â””â”€â”€ ensemble.py          # Ensemble methods
â”‚   â”‚
â”‚   â”œâ”€â”€ features/                 # Feature extraction modules
â”‚   â”‚   â”œâ”€â”€ wordnet_affect.py    # WordNet-Affect emotional embeddings
â”‚   â”‚   â”œâ”€â”€ sentence_roberta.py  # Sentence-level RoBERTa embeddings
â”‚   â”‚   â””â”€â”€ context_window.py    # Multi-turn context processing
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/                 # Analysis tools
â”‚   â”‚   â”œâ”€â”€ information_theory.py # Entropy, MI calculations
â”‚   â”‚   â”œâ”€â”€ class_balance.py     # Class imbalance analysis
â”‚   â”‚   â””â”€â”€ confidence_metrics.py # Prediction confidence analysis
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # Utility functions
â”‚       â”œâ”€â”€ data_loader.py       # IEMOCAP data loading
â”‚       â”œâ”€â”€ preprocessing.py     # Text preprocessing
â”‚       â””â”€â”€ focal_loss.py        # Focal Loss implementation
â”‚
â”œâ”€â”€ scripts/                      # Execution scripts (workflow-ordered)
â”‚   â”œâ”€â”€ 1_data_preparation/
â”‚   â”‚   â”œâ”€â”€ prepare_iemocap.py   # IEMOCAP dataset preparation
â”‚   â”‚   â””â”€â”€ generate_embeddings.py # Generate text embeddings
â”‚   â”‚
â”‚   â”œâ”€â”€ 2_training/
â”‚   â”‚   â”œâ”€â”€ train_baseline.py    # Train baseline models
â”‚   â”‚   â”œâ”€â”€ train_focal_loss.py  # Train with Focal Loss
â”‚   â”‚   â””â”€â”€ train_ensemble.py    # Train ensemble models
â”‚   â”‚
â”‚   â”œâ”€â”€ 3_evaluation/
â”‚   â”‚   â”œâ”€â”€ evaluate_models.py   # Model evaluation
â”‚   â”‚   â”œâ”€â”€ analyze_errors.py    # Error analysis
â”‚   â”‚   â””â”€â”€ generate_reports.py  # Generate performance reports
â”‚   â”‚
â”‚   â””â”€â”€ 4_experiments/
â”‚       â”œâ”€â”€ ablation_study.py    # Component ablation studies
â”‚       â””â”€â”€ parameter_search.py  # Hyperparameter optimization
â”‚
â”œâ”€â”€ configs/                      # Configuration files
â”‚   â”œâ”€â”€ model_configs.yaml       # Model configurations
â”‚   â”œâ”€â”€ training_configs.yaml    # Training parameters
â”‚   â””â”€â”€ focal_loss_params.yaml   # Optimal Focal Loss parameters
â”‚
â”œâ”€â”€ results/                      # Outputs and results
â”‚   â”œâ”€â”€ models/                  # Saved model checkpoints
â”‚   â”œâ”€â”€ logs/                    # Training logs
â”‚   â”œâ”€â”€ figures/                 # Visualizations
â”‚   â””â”€â”€ reports/                 # Performance reports
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”‚   â”œâ”€â”€ data_exploration.ipynb   # Data analysis
â”‚   â””â”€â”€ result_visualization.ipynb # Result visualization
â”‚
â”œâ”€â”€ tests/                        # Unit tests
â”‚   â””â”€â”€ test_focal_loss.py       # Test Focal Loss implementation
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup.py                      # Package setup
â”œâ”€â”€ LICENSE                       # MIT License
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- CUDA 11.0+ (optional, for GPU acceleration)
- IEMOCAP dataset access (requires license agreement)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/SenticCrystal.git
cd SenticCrystal
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download required models and resources:
```bash
python scripts/download_resources.py
```

### Quick Start

1. **Prepare IEMOCAP dataset:**
```bash
python scripts/1_data_preparation/prepare_iemocap.py \
    --data_path /path/to/IEMOCAP \
    --output_path data/processed/
```

2. **Generate embeddings:**
```bash
python scripts/1_data_preparation/generate_embeddings.py \
    --config configs/model_configs.yaml \
    --context_window 5
```

3. **Train model with Focal Loss:**
```bash
python scripts/2_training/train_focal_loss.py \
    --alpha 1.0 \
    --gamma 1.2 \
    --config configs/training_configs.yaml
```

4. **Evaluate performance:**
```bash
python scripts/3_evaluation/evaluate_models.py \
    --model_path results/models/best_model.pth \
    --test_data data/processed/test.pkl
```

## ğŸ“Š Performance

### Text-Only Model (v1.0)

| Configuration | Baseline | With Focal Loss | Improvement |
|--------------|----------|-----------------|-------------|
| Config 146 (RoBERTa) | 72.1% | 70.75% | Balanced* |
| Config 1 (WN+RoBERTa) | 65.8% | 70.10% | +4.30% |
| Config 2 (Context LSTM) | 30.9% | 69.94% | +39.04% |
| **Ensemble (Weighted)** | - | **71.56%** | - |

*Note: While Config 146 shows slight accuracy decrease, it achieves significantly better class balance

### Per-Class Performance (After Focal Loss)

| Emotion | Before FL | After FL | Improvement |
|---------|-----------|----------|-------------|
| Angry | 14.3% | 68% | +53.7% |
| Happy | 47.8% | 77% | +29.2% |
| Sad | 61.4% | 71% | +9.6% |
| Neutral | 10.0% | 66% | +56.0% |

## ğŸ”¬ Key Innovations

1. **Focal Loss Optimization for Emotions**
   - Discovered optimal parameters: Î±=1.0, Î³=1.2 (vs. standard Î³=2.0)
   - Moderate focusing better suited for emotion recognition

2. **Information-Theoretic Diagnosis**
   - Shannon entropy for uncertainty quantification
   - Mutual information for feature importance
   - Context dependency analysis by emotion type

3. **Failed Model Recovery**
   - First demonstration of complete recovery from catastrophic failure
   - 30.9% â†’ 69.94% accuracy through systematic optimization

## ğŸ—ºï¸ Roadmap

### v1.0 - Text-Only (Current)
- âœ… Hierarchical text processing
- âœ… Focal Loss optimization
- âœ… Information-theoretic analysis
- âœ… Ensemble methods

### v2.0 - Multimodal (In Development)
- ğŸ”„ Speech feature integration (Emotion2Vec)
- ğŸ”„ Cross-modal attention mechanisms
- ğŸ”„ Multimodal fusion strategies
- ğŸ”„ Real-time processing pipeline

### v3.0 - Future Enhancements
- â³ Video modality integration
- â³ Generative emotion modeling
- â³ Cross-lingual emotion recognition
- â³ Deployment-ready API

## ğŸ“ Citation

If you use SenticCrystal in your research, please cite:

```bibtex
@article{senticcrystal2025,
  title={SenticCrystal: Information-Theoretic Crystallization of Emotion Recognition},
  author={Your Name},
  journal={arXiv preprint arXiv:xxxx.xxxxx},
  year={2025}
}
```

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- IEMOCAP dataset creators at USC SAIL
- Sentence-Transformers and Hugging Face teams
- WordNet-Affect creators

## ğŸ“§ Contact

For questions and collaborations: cheonkamjeong@gmail.com

---

*"In the complexity of human emotion, we find clarity through crystallization."* - SenticCrystal Philosophy
