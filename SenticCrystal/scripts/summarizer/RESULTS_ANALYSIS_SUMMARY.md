# SenticCrystal ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ (n=10 seeds)

## ğŸ“Š ì „ì²´ ë°ì´í„° ìš”ì•½

- **ì´ ì‹¤í—˜ ìˆ˜**: 1,520 experiments
- **Configuration ìˆ˜**: 152 unique configurations
- **Seeds**: 42-51 (10 seeds)
- **Tasks**: 4-way, 6-way classification

---

## ğŸ† ìµœê³  ì„±ëŠ¥ Configuration

### 4-Way Classification

#### Flat Architecture (Best)
- **Encoder**: sentence-roberta
- **Layer**: last
- **Pool**: mean
- **Classifier**: lstm
- **Weighted F1**: **0.6517 Â± 0.0116**
- **Macro F1**: 0.6435 Â± 0.0129
- **Accuracy**: 0.6495 Â± 0.0117

#### Hierarchical Architecture (Best)
- **Encoder**: sentence-roberta-hier
- **Layer**: avg_last4
- **Pool**: wmean_pos_rev
- **Aggregator**: mean
- **Classifier**: mlp
- **Weighted F1**: **0.6846 Â± 0.0109** â­
- **Macro F1**: 0.6783 Â± 0.0116
- **Accuracy**: 0.6836 Â± 0.0107

**ğŸ“ˆ Performance Gain: +5.04% (Hierarchical > Flat)**

---

### 6-Way Classification

#### Flat Architecture (Best)
- **Encoder**: sentence-roberta
- **Layer**: avg_last4
- **Pool**: mean
- **Classifier**: lstm
- **Weighted F1**: **0.5269 Â± 0.0104**
- **Macro F1**: 0.5147 Â± 0.0115
- **Accuracy**: 0.5294 Â± 0.0108

#### Hierarchical Architecture (Best)
- **Encoder**: sentence-roberta-hier
- **Layer**: last
- **Pool**: wmean_pos_rev
- **Aggregator**: attn
- **Classifier**: lstm
- **Weighted F1**: **0.5424 Â± 0.0119** â­
- **Macro F1**: 0.5254 Â± 0.0113
- **Accuracy**: 0.5415 Â± 0.0123

**ğŸ“ˆ Performance Gain: +2.95% (Hierarchical > Flat)**

---

## ğŸ§ª í†µê³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼

### âœ… TEST 1: Flat vs Hierarchical (Main Hypothesis)

#### 4-Way Classification
```
Hierarchical: 0.6846 Â± 0.0104
Flat:         0.6517 Â± 0.0110
```
- **Mann-Whitney U Test**: p = 0.000220 ***
- **Effect Size (Cohen's d)**: 2.9194 (large)
- **Improvement**: +3.29% absolute, +5.04% relative
- **âœ… ê²°ë¡ **: Hierarchicalì´ Flatë³´ë‹¤ **í†µê³„ì ìœ¼ë¡œ ë§¤ìš° ìœ ì˜í•˜ê²Œ** ìš°ìˆ˜í•¨

#### 6-Way Classification
```
Hierarchical: 0.5424 Â± 0.0119
Flat:         0.5269 Â± 0.0104
```
- **Mann-Whitney U Test**: p = 0.000116 ***
- **Effect Size (Cohen's d)**: 2.4086 (large)
- **Improvement**: +1.55% absolute, +2.95% relative
- **âœ… ê²°ë¡ **: Hierarchicalì´ Flatë³´ë‹¤ **í†µê³„ì ìœ¼ë¡œ ë§¤ìš° ìœ ì˜í•˜ê²Œ** ìš°ìˆ˜í•¨

---

### âœ… TEST 2: Encoder Comparison (Flat Only)

#### 4-Way Classification
```
sentence-roberta: 0.6463 Â± 0.0104
roberta-base:     0.6348 Â± 0.0155
bert-base:        0.6213 Â± 0.0157
```

**Pairwise Comparisons:**
1. **sentence-roberta vs bert-base**
   - p < 0.001 ***, Cohen's d = 1.8682 (large)
   - Improvement: +4.03%

2. **sentence-roberta vs roberta-base**
   - p < 0.001 ***, Cohen's d = 0.8706 (large)
   - Improvement: +1.82%

3. **roberta-base vs bert-base**
   - p < 0.001 ***, Cohen's d = 0.8587 (large)
   - Improvement: +2.17%

**âœ… ê²°ë¡ **: sentence-roberta > roberta-base > bert-base (ëª¨ë‘ í†µê³„ì ìœ¼ë¡œ ìœ ì˜)

#### 6-Way Classification
```
sentence-roberta: 0.5206 Â± 0.0145
roberta-base:     0.4946 Â± 0.0190
bert-base:        0.4783 Â± 0.0240
```
- ë™ì¼í•œ íŒ¨í„´ í™•ì¸ (ëª¨ë‘ p < 0.001)

---

### âœ… TEST 3: Aggregator Comparison (Hierarchical Only)

#### 4-Way Classification
```
mean:     0.6711 Â± 0.0138
attn:     0.6702 Â± 0.0112
expdecay: 0.6698 Â± 0.0150
sum:      0.6681 Â± 0.0124
lstm:     0.6522 Â± 0.0205
```

**Key Findings:**
1. **mean vs lstm**: p < 0.001 ***, d = 1.0709 (large), +2.89%
2. **attn vs lstm**: p < 0.001 ***, d = 1.0811 (large), +2.75%
3. **mean vs attn**: p = 0.643 (not significant)
4. **mean vs sum**: p = 0.058 (marginal)

**âœ… ê²°ë¡ **: mean, attn, expdecay, sum ëª¨ë‘ ë¹„ìŠ·í•œ ì„±ëŠ¥ (ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ)
            lstm aggregatorëŠ” ìœ ì˜í•˜ê²Œ ë‚®ì€ ì„±ëŠ¥

#### 6-Way Classification
```
attn:     0.5326 Â± 0.0121 â­
mean:     0.5287 Â± 0.0132
sum:      0.5286 Â± 0.0131
expdecay: 0.5270 Â± 0.0140
lstm:     0.5149 Â± 0.0220
```

**Key Findings:**
1. **attn vs lstm**: p < 0.001 ***, d = 0.9899 (large), +3.43%
2. **attn vs expdecay**: p = 0.008 **, d = 0.4287 (small), +1.07%
3. **attn vs sum**: p = 0.015 *, d = 0.3163 (small), +0.76%
4. **attn vs mean**: p = 0.036 * (marginal)

**âœ… ê²°ë¡ **: attnì´ 6-wayì—ì„œëŠ” best aggregator (meanê³¼ëŠ” ê·¼ì†Œí•œ ì°¨ì´)

---

### âœ… TEST 4: Classifier Comparison (MLP vs LSTM)

#### 4-Way Classification
**Flat:**
- MLP: 0.6356 Â± 0.0164
- LSTM: 0.6327 Â± 0.0182
- p = 0.092 (not significant), d = 0.1675

**Hierarchical:**
- MLP: 0.6660 Â± 0.0170
- LSTM: 0.6665 Â± 0.0161
- p = 0.701 (not significant), d = 0.0298

**âœ… ê²°ë¡ **: MLPì™€ LSTM ê°„ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ (4-way)

#### 6-Way Classification
**Flat:**
- MLP: 0.5018 Â± 0.0206
- LSTM: 0.4938 Â± 0.0266
- p = 0.006 **, d = 0.3335 (small), +1.61%

**Hierarchical:**
- MLP: 0.5264 Â± 0.0156
- LSTM: 0.5264 Â± 0.0172
- p = 0.992 (not significant)

**âœ… ê²°ë¡ **: Flatì—ì„œëŠ” MLPê°€ ì•½ê°„ ìš°ìˆ˜, Hierarchicalì—ì„œëŠ” ì°¨ì´ ì—†ìŒ

---

### âœ… TEST 5: Layer Selection (last vs avg_last4)

#### 4-Way Classification
**Flat:**
- avg_last4: 0.6343 Â± 0.0157
- last: 0.6369 Â± 0.0172
- p = 0.200 (not significant)

**Hierarchical:**
- avg_last4: 0.6689 Â± 0.0162
- last: 0.6636 Â± 0.0176
- p = 0.007 **, d = 0.3125 (small), +0.80%

**âœ… ê²°ë¡ **: Hierarchicalì—ì„œëŠ” avg_last4ê°€ ì•½ê°„ ìš°ìˆ˜

#### 6-Way Classification
**Flat:**
- avg_last4: 0.4997 Â± 0.0231
- last: 0.4959 Â± 0.0249
- p = 0.161 (not significant)

**Hierarchical:**
- avg_last4: 0.5231 Â± 0.0171
- last: 0.5296 Â± 0.0150
- p = 0.001 **, d = 0.4000 (small), lastê°€ +1.22% ìš°ìˆ˜!

**âœ… ê²°ë¡ **: 6-way hierarchicalì—ì„œëŠ” lastê°€ ë” ìš°ìˆ˜

---

### âœ… TEST 6: Pooling Strategy

#### 4-Way Classification
**Flat:**
- mean: 0.6375 Â± 0.0161
- wmean_pos_rev: 0.6351 Â± 0.0166
- attn: 0.6302 Â± 0.0164
- wmean_pos_rev vs mean: p = 0.231 (not significant)

**Hierarchical:**
- wmean_pos_rev: 0.6700 Â± 0.0151
- mean: 0.6683 Â± 0.0166
- p = 0.378 (not significant)

**âœ… ê²°ë¡ **: meanê³¼ wmean_pos_rev ê°„ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ

#### 6-Way Classification
**Flat:**
- mean: 0.5032 Â± 0.0226
- wmean_pos_rev: 0.5005 Â± 0.0226
- attn: 0.4897 Â± 0.0249
- attn vs mean: p < 0.001 ***, d = 0.5659 (medium), -2.68%

**Hierarchical:**
- mean: 0.5279 Â± 0.0153
- wmean_pos_rev: 0.5249 Â± 0.0174
- p = 0.098 (not significant)

**âœ… ê²°ë¡ **: meanì´ ê°€ì¥ ì•ˆì •ì , attn poolingì€ 6-way flatì—ì„œ ì„±ëŠ¥ ì €í•˜

---

## ğŸ“ˆ ì£¼ìš” ë°œê²¬ (Key Findings)

### 1. ì•„í‚¤í…ì²˜ ë¹„êµ
âœ… **Hierarchical architectureê°€ Flatë³´ë‹¤ ëª…í™•íˆ ìš°ìˆ˜**
- 4-way: +5.04% improvement (p < 0.001, d = 2.92)
- 6-way: +2.95% improvement (p < 0.001, d = 2.41)
- Large effect sizeë¡œ ì‹¤ì§ˆì ìœ¼ë¡œë„ ì˜ë¯¸ ìˆëŠ” ê°œì„ 

### 2. Encoder ì„ íƒ
âœ… **sentence-robertaê°€ ìµœê³  ì„±ëŠ¥**
- sentence-roberta > roberta-base > bert-base
- ëª¨ë“  ë¹„êµì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ (p < 0.001)
- 4-way: sentence-robertaê°€ bert-base ëŒ€ë¹„ +4.03%

### 3. Aggregator ì„ íƒ (Hierarchical)
âœ… **mean, attn, sum, expdecay ëª¨ë‘ ë¹„ìŠ·í•œ ì„±ëŠ¥**
- 4-way: mean, attn ê¶Œì¥ (lstmì€ ì œì™¸)
- 6-way: attnì´ slightly better (p < 0.05)
- lstm aggregatorëŠ” ì„±ëŠ¥ì´ ìœ ì˜í•˜ê²Œ ë‚®ìŒ (ì œì™¸ ê¶Œì¥)

### 4. Classifier ì„ íƒ
âœ… **MLPì™€ LSTM ê°„ í° ì°¨ì´ ì—†ìŒ**
- ëŒ€ë¶€ë¶„ ê²½ìš° ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ
- 6-way flatì—ì„œë§Œ MLPê°€ ì•½ê°„ ìš°ìˆ˜ (p < 0.01)

### 5. Layer Selection
âš ï¸ **Taskì™€ architectureì— ë”°ë¼ ë‹¤ë¦„**
- 4-way hierarchical: avg_last4ê°€ ì•½ê°„ ìš°ìˆ˜
- 6-way hierarchical: lastê°€ ì•½ê°„ ìš°ìˆ˜
- Effect sizeê°€ smallì´ë¯€ë¡œ í° ì°¨ì´ëŠ” ì•„ë‹˜

### 6. Pooling Strategy
âœ… **mean poolingì´ ê°€ì¥ ì•ˆì •ì **
- wmean_pos_revë„ ë¹„ìŠ·í•œ ì„±ëŠ¥
- attn poolingì€ 6-way flatì—ì„œ ì„±ëŠ¥ ì €í•˜

---

## ğŸ“Š Seed ê°„ ë¶„ì‚° (Variance across seeds)

```
Task  Type          Acc Std   Macro F1 Std   Weighted F1 Std
4way  flat          0.0110    0.0122         0.0108
4way  hierarchical  0.0140    0.0140         0.0141
6way  flat          0.0112    0.0156         0.0127
6way  hierarchical  0.0148    0.0136         0.0138
```

**ë¶„ì„:**
- Hierarchicalì´ Flatë³´ë‹¤ ì•½ê°„ ë†’ì€ variance (0.014 vs 0.011)
- ê·¸ëŸ¬ë‚˜ ì—¬ì „íˆ ë‚®ì€ ìˆ˜ì¤€ (~1.4%)
- 10 seedsë¡œ ì•ˆì •ì ì¸ í‰ê°€ ê°€ëŠ¥

---

## ğŸ¯ ë…¼ë¬¸ì„ ìœ„í•œ ê¶Œì¥ ì‚¬í•­

### 1. Main Claims (ê°•ë ¥í•œ ì¦ê±°)
âœ… **Hierarchical architectureê°€ ìš°ìˆ˜í•˜ë‹¤**
- p < 0.001, large effect size (d > 2.4)
- 4-way: 68.46% vs 65.17% (+5.04%)
- 6-way: 54.24% vs 52.69% (+2.95%)

### 2. Supporting Claims (ê°•í•œ ì¦ê±°)
âœ… **sentence-robertaê°€ ìµœê³  encoder**
- p < 0.001, large effect size
- ëª¨ë“  taskì—ì„œ ì¼ê´€ëœ ìš°ìˆ˜ì„±

âœ… **mean/attn aggregator ê¶Œì¥**
- lstm aggregator ì œì™¸ (ìœ ì˜í•˜ê²Œ ë‚®ì€ ì„±ëŠ¥)

### 3. Interesting Observations (ì•½í•œ ì¦ê±°)
âš ï¸ **Layer selectionì€ task-dependent**
- Small effect size
- ì¶”ê°€ ë¶„ì„ í•„ìš”

âš ï¸ **MLP vs LSTMì€ ë¹„ìŠ·**
- ëŒ€ë¶€ë¶„ ìœ ì˜í•œ ì°¨ì´ ì—†ìŒ

---

## ğŸ“‹ í•„ìš”í•œ ì¶”ê°€ í†µê³„ í…ŒìŠ¤íŠ¸

### 1. Multiple Comparison Correction
í˜„ì¬ ë§ì€ pairwise comparisonì„ ìˆ˜í–‰í–ˆìœ¼ë¯€ë¡œ:
- **Bonferroni correction** ì ìš© ê¶Œì¥
- **Holm-Bonferroni** ë˜ëŠ” **FDR correction** ê³ ë ¤

### 2. Effect Size Confidence Intervals
- Cohen's dì˜ 95% CI ê³„ì‚°
- Bootstrap ë°©ë²• ì‚¬ìš©

### 3. Best Configuration Validation
- ìµœê³  configurationì— ëŒ€í•´ ì¶”ê°€ seed (52-61)ë¡œ ê²€ì¦
- Generalization í™•ì¸

### 4. Task Difficulty Analysis
- 4-way vs 6-way ì„±ëŠ¥ ì°¨ì´ ë¶„ì„
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì˜í–¥ ë¶„ì„

### 5. Ablation Study
- ê° componentì˜ ê¸°ì—¬ë„ ì •ëŸ‰í™”
- SHAP ë˜ëŠ” feature importance

---

## ğŸ’¡ ë…¼ë¬¸ ì‘ì„± íŒ

### Abstract/Introductionì— í¬í•¨í•  ìˆ˜ì¹˜
- "Hierarchical architecture achieves **5.04%** relative improvement (p < 0.001)"
- "sentence-roberta encoder outperforms BERT by **4.03%** (p < 0.001)"
- "Results validated across **10 random seeds** (42-51)"

### Results Section
- Best configurations table (LaTeX ì½”ë“œ ì œê³µë¨)
- Statistical test results table (p-values, effect sizes)
- Ablation study results

### Discussion
- Why hierarchical works better (document-level context)
- Why sentence-roberta is best (pre-trained on sentence tasks)
- Limitations (computational cost, variance)

### Figures ì¶”ì²œ
1. Bar chart: Flat vs Hierarchical comparison
2. Box plot: Seed variance visualization
3. Heatmap: Configuration performance matrix
4. Line plot: Performance vs. model size

---

## ğŸ“ LaTeX Table ì˜ˆì‹œ (ë…¼ë¬¸ìš©)

```latex
\begin{table*}[t]
\centering
\caption{Performance Comparison: Flat vs. Hierarchical Architecture (n=10 seeds)}
\label{tab:main_results}
\begin{tabular}{lccccc}
\toprule
\textbf{Task} & \textbf{Architecture} & \textbf{Weighted F1} & \textbf{Macro F1} & \textbf{Accuracy} & \textbf{p-value} \\
\midrule
\multirow{2}{*}{4-way} 
  & Flat & $0.6517 \pm 0.0116$ & $0.6435 \pm 0.0129$ & $0.6495 \pm 0.0117$ & \multirow{2}{*}{$<0.001$***} \\
  & Hierarchical & $\mathbf{0.6846 \pm 0.0109}$ & $\mathbf{0.6783 \pm 0.0116}$ & $\mathbf{0.6836 \pm 0.0107}$ & \\
\midrule
\multirow{2}{*}{6-way} 
  & Flat & $0.5269 \pm 0.0104$ & $0.5147 \pm 0.0115$ & $0.5294 \pm 0.0108$ & \multirow{2}{*}{$<0.001$***} \\
  & Hierarchical & $\mathbf{0.5424 \pm 0.0119}$ & $\mathbf{0.5254 \pm 0.0113}$ & $\mathbf{0.5415 \pm 0.0123}$ & \\
\bottomrule
\end{tabular}
\end{table*}
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ
- [x] 1,520 experiments collected
- [x] All 10 seeds (42-51) present
- [x] No missing configurations

### í†µê³„ ë¶„ì„ ì™„ë£Œ
- [x] Main hypothesis tested (Flat vs Hier)
- [x] Encoder comparison
- [x] Aggregator comparison
- [x] Classifier comparison
- [x] Layer selection analysis
- [x] Pooling strategy analysis
- [x] Effect sizes calculated
- [x] LaTeX tables generated

### ì¶”ê°€ ì‘ì—… í•„ìš”
- [ ] Multiple comparison correction
- [ ] Effect size confidence intervals
- [ ] Visualizations (plots)
- [ ] Confusion matrices
- [ ] Error analysis
- [ ] Computational cost analysis

---

## ğŸ‰ ê²°ë¡ 

**Hierarchical document modelingì´ flat baselineë³´ë‹¤ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì„.**

í•µì‹¬ ìˆ˜ì¹˜:
- 4-way: **68.46%** (hierarchical) vs 65.17% (flat) â†’ +5.04% 
- 6-way: **54.24%** (hierarchical) vs 52.69% (flat) â†’ +2.95%
- p < 0.001, Cohen's d > 2.4 (large effect)

ì´ëŠ” ë¬¸ì„œ ìˆ˜ì¤€ì˜ êµ¬ì¡°ì  ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” hierarchical architectureì˜ ìš°ìˆ˜ì„±ì„ ì…ì¦í•©ë‹ˆë‹¤.
